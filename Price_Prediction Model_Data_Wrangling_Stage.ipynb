{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60f3186",
   "metadata": {},
   "source": [
    "# Capstone Two: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bbd707",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81029b09",
   "metadata": {},
   "source": [
    "The purpose of this data wrangling exercise is to ensur I have sufficient and quality data to use in developing a price prediction model. \n",
    "\n",
    "The dataset used in this project was obtained from https://www.kaggle.com/datasets/ahmedshahriarsakib/usa-real-estate-dataset \n",
    "The Kaggle command API is !kaggle datasets download -d ahmedshahriarsakib/usa-real-estate-dataset\n",
    "\n",
    "The definitions of the columns in the dataset are:\n",
    "status = Housing status - ready for sale or, ready to build\n",
    "bed  = number of beds\n",
    "bath = number of bathrooms\n",
    "acre_lot = Property / Land size in acres\n",
    "city = name of the city where house is located\n",
    "state = name of the state\n",
    "zip_code = postal code of the area\n",
    "house_size = square footage for the house\n",
    "prev_sold_date = previous date when the house was last sold\n",
    "price = Housing price, it is either the current listing price or recently sold price if the house was sold recently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a17f3f",
   "metadata": {},
   "source": [
    "### 1.1 Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e0044",
   "metadata": {},
   "source": [
    "Clean the data and ensure it is sufficient to test whether house attributes such as number of bedrooms, bathrooms, as well as location and lot_size correlate with price. Also, if I can predict housing prices based on the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d1763a",
   "metadata": {},
   "source": [
    "## 2. Imported Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and libraries\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e927b9ba",
   "metadata": {},
   "source": [
    "## 3. Load the Real Estate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad92a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset\n",
    "df = pd.read_csv('realtor_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93627307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original dataset\n",
    "df1 = df.copy()\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f58c1f",
   "metadata": {},
   "source": [
    "## 4. Data Definitions: Column Descriptions and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffdf04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b254e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting Unique Values\n",
    "df1.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0edf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent of unique values\n",
    "df1.nunique() / df1.size*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54df683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'zip_code' column to category\n",
    "df1['zip_code'] = df1['zip_code'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf7515",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3504916b",
   "metadata": {},
   "source": [
    "### 5.1 Missing and NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = pd.concat([df1.isna().sum(), 100 * df1.isna().mean()], axis=1)\n",
    "missing.columns=['count', '%']\n",
    "missing.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1516a31",
   "metadata": {},
   "source": [
    "The prev_sold_date feature has the highest numbe rof missing values. This feature does not play an important role in meeting this project's objective but I would not drop it for now. Acre_lot and house_size are important to meeting my objective; these fatures will be dropped because I believe I have sufficient data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16330d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values from 'acre_lot' and 'house_size' columns\n",
    "df1.dropna(subset=['acre_lot', 'house_size'], inplace=True)\n",
    "\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing values in the DataFrame\n",
    "missing_values = df1.isna()\n",
    "\n",
    "#Display the count of missing values\n",
    "print(missing_values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e655e",
   "metadata": {},
   "source": [
    "Earlier, there were zero entries in the in the 'price' and 'acre_lot' columns. Drop those values from the price column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65461a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of values in the 'price' column that are either 0.0 or NaN\n",
    "price_zero_or_nan = df1['price'].isin([0, 0.0, float('nan')]).sum()\n",
    "\n",
    "print(f\"Number of values in the 'price' column that are either 0.0 or NaN:\", price_zero_or_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94bb27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_bed_bath = df1[['bed', 'bath']].isna().sum(axis=1)\n",
    "missing_bed_bath.value_counts()/len(missing_bed_bath) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47443f69",
   "metadata": {},
   "source": [
    "Over 96% of 'bed' and 'bath' data have no missing values, 2% are missing both values, and about 1.5% have a value missing either in the 'bed' or 'bath' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e303a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the 'price' column and drop values equal to 0 or 0.0\n",
    "drop_indices = []\n",
    "for index, value in df1['price'].items():\n",
    "    if value == 0 or value == 0.0:\n",
    "        drop_indices.append(index)\n",
    "\n",
    "# Drop rows in the drop_indices list\n",
    "df1.drop(drop_indices, inplace=True, errors='ignore')\n",
    "\n",
    "# Drop rows where both 'bed' and 'bath' columns have missing values\n",
    "df1.dropna(subset=['bed', 'bath'], inplace=True)\n",
    "\n",
    "# Reset index after dropping rows\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Display results\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f9929",
   "metadata": {},
   "source": [
    "The column with the date when a house was previously sold has a lot missing data. I would not want to drop theses values because it may contain other useful data. Therefore I would impute with the current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'prev_sold_date' to datetime\n",
    "df1['prev_sold_date'] = pd.to_datetime(df1['prev_sold_date'], errors='coerce')\n",
    "\n",
    "df1['prev_sold_date'] = df1['prev_sold_date'].dt.strftime(\"%y - %m - %d\")\n",
    "\n",
    "# Fill missing values in 'prev_sold_date' column with today's date\n",
    "df1['prev_sold_date'].fillna(pd.Timestamp.today().date(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8855fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine missingness\n",
    "sorted_df1 = df1.sort_values(by='price')\n",
    "msno.matrix(sorted_df1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876e51f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9155f",
   "metadata": {},
   "source": [
    "### 5.2 Handling Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_df1 = df1[df1.duplicated()]\n",
    "duplicate_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088235d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop_duplicates(subset=[\"bed\", \"bath\", \"acre_lot\", \"city\", \"state\", \"zip_code\", \"house_size\", \"price\"], inplace=True)\n",
    "\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8084d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413268e",
   "metadata": {},
   "source": [
    "### 5.3 Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c591a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Outliers\n",
    "numeric_cols = ['bed', 'bath', 'acre_lot', 'house_size', 'price']\n",
    "seventy_fifth = df1[numeric_cols].quantile(0.75)\n",
    "twenty_fifth = df[numeric_cols].quantile(0.25)\n",
    "df1_iqr = seventy_fifth - twenty_fifth\n",
    "\n",
    "upper_threshold = seventy_fifth + (1.5 * df1_iqr)\n",
    "\n",
    "lower_threshold = twenty_fifth - (1.5 * df1_iqr)\n",
    "\n",
    "print('Upper_threshold: ')\n",
    "print(upper_threshold)\n",
    "\n",
    "print('\\nLower_threshold: ')\n",
    "print(lower_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_less_than_536000 = (df1['price'] <= 536000).sum()\n",
    "print(count_less_than_536000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_more_than_1520000 = (df1['price'] > 1520000).sum()\n",
    "print(count_more_than_1520000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac982c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_acre_lot = (df1['acre_lot'] == 0.0).sum()\n",
    "print(null_acre_lot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a12298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_less_10000 = (df1['price'] <= 20000).sum()\n",
    "print(price_less_10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457e9b72",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f156a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc94c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
